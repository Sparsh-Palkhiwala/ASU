{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1RqT_Nv1CAbA",
        "outputId": "d3b5ea70-07be-4f63-ebf1-bd1dbbc6d492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XmNn8oqUCps5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "from sklearn.metrics import accuracy_score\n",
        "import random as rand\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pmY4pxgvC9Vn"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Sem 1/Data Mining/HW/DATASET/HW3 Dataset/data.csv\").to_numpy()\n",
        "labels = pd.read_csv(\"/content/drive/MyDrive/Sem 1/Data Mining/HW/DATASET/HW3 Dataset/label.csv\",header = None).to_numpy().flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "vNjuZcVCTbIv"
      },
      "outputs": [],
      "source": [
        "def random_centroids(data, K):\n",
        "    centroids = []\n",
        "\n",
        "    for i in range(K):\n",
        "        centroid = data[rand.randint(0, 149)]\n",
        "        centroids.append(centroid)\n",
        "    return centroids\n",
        "\n",
        "\n",
        "def assign_cluster(data, centroids):\n",
        "    assignments = []\n",
        "\n",
        "    for data_point in data:\n",
        "        dist_point_clust = []\n",
        "\n",
        "        for centroid in centroids:\n",
        "            d_clust = np.linalg.norm(np.array(data_point) - np.array(centroid))\n",
        "            dist_point_clust.append(d_clust)\n",
        "\n",
        "        assignment = np.argmin(dist_point_clust)\n",
        "        assignments.append(assignment)\n",
        "\n",
        "    return assignments\n",
        "\n",
        "def new_centroids(data, centroids, assignments, K):\n",
        "    new_centroids = []\n",
        "    for i in range(K):\n",
        "        pt_cluster = []\n",
        "        for x in range(len(data)):\n",
        "                if (assignments[x] == i):\n",
        "                    pt_cluster.append(data[x])\n",
        "        mean_c = np.mean(pt_cluster, axis=0)\n",
        "        new_centroids.append(mean_c)\n",
        "\n",
        "    return new_centroids\n",
        "\n",
        "def sse(data, assignments, centroids):\n",
        "    errors = []\n",
        "\n",
        "    for i in range(len(data)):\n",
        "\n",
        "        centroid = centroids[assignments[i]]\n",
        "        error = np.linalg.norm(np.array(data[i]) - np.array(centroid))\n",
        "        errors.append(error**2)\n",
        "\n",
        "    sse = sum(errors)\n",
        "\n",
        "    return sse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdU4rSx_I67N"
      },
      "source": [
        "K-means Execution and Evaluation:\n",
        "\n",
        "\n",
        "\n",
        "*   Iterates over each distance function.\n",
        "*   Calls the k_means function for the current distance function and records the resulting cluster labels, centroids, and SSE.\n",
        "*   Evaluates clustering performance by comparing the obtained cluster labels with the true labels (labels) and calculates accuracy.\n",
        "Stores SSE and Accuracy in the results dictionary.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "V8ENQY372Wqo",
        "outputId": "641ff070-9832-4568-94cb-e7e6c6594d57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Euclidean K-means - SSE: 25517481494.00, Accuracy: 13.39%\n",
            "Cosine K-means - SSE: 697.81, Accuracy: 5.59%\n",
            "Jaccard K-means - SSE: 3653.15, Accuracy: 7.95%\n"
          ]
        }
      ],
      "source": [
        "def euclidean_distance(x1, x2):\n",
        "    return np.linalg.norm(x1 - x2)\n",
        "\n",
        "def cosine_similarity(x1, x2):\n",
        "    dot_product = np.dot(x1, x2)\n",
        "    norm_x1 = np.linalg.norm(x1)\n",
        "    norm_x2 = np.linalg.norm(x2)\n",
        "    similarity = dot_product / (norm_x1 * norm_x2)\n",
        "    return 1 - similarity\n",
        "\n",
        "def jaccard_similarity(x1, x2):\n",
        "    intersection = np.sum(np.minimum(x1, x2))\n",
        "    union = np.sum(np.maximum(x1, x2))\n",
        "    similarity = intersection / union\n",
        "    return 1 - similarity\n",
        "\n",
        "\n",
        "def k_means(data, k, distance_function, max_iters=100):\n",
        "    n_samples, n_features = data.shape\n",
        "    centroids = data[np.random.choice(n_samples, k, replace=False)]\n",
        "    labels = np.zeros(n_samples)\n",
        "\n",
        "    for _ in range(max_iters):\n",
        "        for i in range(n_samples):\n",
        "            distances = [distance_function(data[i], centroid) for centroid in centroids]\n",
        "            labels[i] = np.argmin(distances)\n",
        "\n",
        "\n",
        "        for j in range(k):\n",
        "            mask = labels == j\n",
        "            centroids[j] = np.mean(data[mask], axis=0)\n",
        "\n",
        "    sse = sum([distance_function(data[i], centroids[int(labels[i])])**2 for i in range(n_samples)])\n",
        "\n",
        "    return labels, centroids, sse\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Sem 1/Data Mining/HW/DATASET/HW3 Dataset/data.csv\",header = None).to_numpy()\n",
        "labels = pd.read_csv(\"/content/drive/MyDrive/Sem 1/Data Mining/HW/DATASET/HW3 Dataset/label.csv\",header = None).to_numpy()\n",
        "\n",
        "# Set the number of clusters (k)\n",
        "k = len(np.unique(labels))  # Number of categories in labels\n",
        "\n",
        "distance_functions = [euclidean_distance, cosine_similarity, jaccard_similarity]\n",
        "distance_function_names = ['Euclidean', 'Cosine', 'Jaccard']\n",
        "\n",
        "results = {}\n",
        "\n",
        "\n",
        "for distance_function, distance_function_name in zip(distance_functions, distance_function_names):\n",
        "\n",
        "    cluster_labels, cluster_centroids, sse = k_means(data, k, distance_function)\n",
        "    accuracy = np.sum(cluster_labels == labels.squeeze()) / len(labels)\n",
        "    results[distance_function_name] = {'SSE': sse, 'Accuracy': accuracy}\n",
        "\n",
        "for method, result in results.items():\n",
        "    print(f\"{method} K-means - SSE: {result['SSE']:.2f}, Accuracy: {result['Accuracy'] * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wtt1gcx2JwF7"
      },
      "source": [
        "Q1 - Compare SEE\n",
        "\n",
        "\n",
        "1. Euclidean K-means - SSE: 25517481494.00, Accuracy: 13.39%\n",
        "2. Cosine K-means - SSE: 697.81, Accuracy: 5.59%\n",
        "3. Jaccard K-means - SSE: 3653.15, Accuracy: 7.95%.\n",
        "\n",
        "We see that Cosine Distance function has the lowest sum of squared errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WGsNflAJfg8"
      },
      "source": [
        "Majority Vte Execution and Evaluation\n",
        "* Iterates over each distance function.\n",
        "* Calls the k_means_majority_vote function for the current distance function and records the accuracy.\n",
        "* Stores accuracy in the accuracies dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YynnsUvnCPVb",
        "outputId": "6fd80755-4322-4623-8723-1670149fd0ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Euclidean K-means with Majority Vote - Accuracy: 59.72%\n",
            "Cosine K-means with Majority Vote - Accuracy: 57.37%\n",
            "Jaccard K-means with Majority Vote - Accuracy: 60.12%\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Sem 1/Data Mining/HW/DATASET/HW3 Dataset/data.csv\", header=None).to_numpy()\n",
        "labels = pd.read_csv(\"/content/drive/MyDrive/Sem 1/Data Mining/HW/DATASET/HW3 Dataset/label.csv\", header=None).to_numpy().flatten()\n",
        "\n",
        "def k_means_majority_vote(data, k, distance_function, max_iters=100):\n",
        "    n_samples, n_features = data.shape\n",
        "    centroids = data[np.random.choice(n_samples, k, replace=False)]\n",
        "    assigned_labels = np.zeros(n_samples)\n",
        "\n",
        "    for _ in range(max_iters):\n",
        "        for i in range(n_samples):\n",
        "            distances = [distance_function(data[i], centroid) for centroid in centroids]\n",
        "            assigned_labels[i] = np.argmin(distances)\n",
        "\n",
        "        for j in range(k):\n",
        "            mask = assigned_labels == j\n",
        "            centroids[j] = np.mean(data[mask], axis=0)\n",
        "\n",
        "    # Label each cluster using majority vote\n",
        "    cluster_labels = np.zeros(k)\n",
        "    for j in range(k):\n",
        "        cluster_mask = assigned_labels == j\n",
        "        majority_label = np.argmax(np.bincount(labels[cluster_mask].astype(int)))\n",
        "        cluster_labels[j] = majority_label\n",
        "\n",
        "    # Assign cluster labels to data points\n",
        "    predicted_labels = np.array([cluster_labels[int(label)] for label in assigned_labels])\n",
        "\n",
        "    accuracy = np.sum(predicted_labels == labels.squeeze()) / len(labels)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "distance_functions = [euclidean_distance, cosine_similarity, jaccard_similarity]\n",
        "distance_function_names = ['Euclidean', 'Cosine', 'Jaccard']\n",
        "\n",
        "\n",
        "accuracies = {}\n",
        "\n",
        "for distance_function, distance_function_name in zip(distance_functions, distance_function_names):\n",
        "\n",
        "    accuracy = k_means_majority_vote(data, k, distance_function)\n",
        "    accuracies[distance_function_name] = accuracy\n",
        "\n",
        "for method, accuracy in accuracies.items():\n",
        "    print(f\"{method} K-means with Majority Vote - Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYrJPjdNKEC8"
      },
      "source": [
        "Q2 We observe the following results\n",
        "\n",
        "\n",
        "1.   Euclidean K-means with Majority Vote - Accuracy: 59.72%\n",
        "2.   Cosine K-means with Majority Vote - Accuracy: 57.37%\n",
        "3.   Jaccard K-means with Majority Vote - Accuracy: 60.12%\n",
        "\n",
        "The choice of distance metric can significantly impact the performance of clustering algorithms. The effectiveness of a distance metric depends on the characteristics of the data and the underlying structure of the clusters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "n30U83duaFeX",
        "outputId": "72eb7b2e-37fd-476f-a867-6168233489fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Euclidean K-means - Iterations: 48, SSE: 25392039606.17, Time to Converge: 57.5660 seconds\n",
            "Cosine K-means - Iterations: 59, SSE: 682.22, Time to Converge: 124.8682 seconds\n",
            "Jaccard K-means - Iterations: 69, SSE: 3660.35, Time to Converge: 182.2073 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "# K-means algorithm with stop criteria\n",
        "def k_means_stop_criteria(data, k, distance_function, max_iters=500, tolerance=1e-4):\n",
        "    n_samples, n_features = data.shape\n",
        "    centroids = data[np.random.choice(n_samples, k, replace=False)]\n",
        "    assigned_labels = np.zeros(n_samples)\n",
        "\n",
        "    for iter_count in range(max_iters):\n",
        "        for i in range(n_samples):\n",
        "            distances = [distance_function(data[i], centroid) for centroid in centroids]\n",
        "            assigned_labels[i] = np.argmin(distances)\n",
        "\n",
        "        new_centroids = np.array([np.mean(data[assigned_labels == j], axis=0) for j in range(k)])\n",
        "\n",
        "        # Check stop criteria\n",
        "        if np.all(np.abs(new_centroids - centroids) < tolerance):\n",
        "            break\n",
        "        centroids = new_centroids\n",
        "\n",
        "    sse = sum([distance_function(data[i], centroids[int(assigned_labels[i])])**2 for i in range(n_samples)])\n",
        "\n",
        "    return assigned_labels, centroids, iter_count + 1, sse\n",
        "\n",
        "\n",
        "distance_functions = [euclidean_distance, cosine_similarity, jaccard_similarity]\n",
        "distance_function_names = ['Euclidean', 'Cosine', 'Jaccard']\n",
        "results = {}\n",
        "\n",
        "# Apply K-means algorithm with stop criteria for each distance function\n",
        "for distance_function, distance_function_name in zip(distance_functions, distance_function_names):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Run K-means with stop criteria\n",
        "    cluster_labels, cluster_centroids, num_iterations, sse = k_means_stop_criteria(data, k, distance_function)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Store information in the dictionary\n",
        "    results[distance_function_name] = {\n",
        "        'Cluster Labels': cluster_labels,\n",
        "        'Centroids': cluster_centroids,\n",
        "        'Num Iterations': num_iterations,\n",
        "        'SSE': sse,\n",
        "        'Time to Converge': end_time - start_time\n",
        "    }\n",
        "\n",
        "# Display results\n",
        "for method, result in results.items():\n",
        "    print(f\"{method} K-means - Iterations: {result['Num Iterations']}, SSE: {result['SSE']:.2f}, Time to Converge: {result['Time to Converge']:.4f} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xM1vPwvNLYii"
      },
      "source": [
        "Q3 The result we are :\n",
        "1. Euclidean K-means - Iterations: 48, SSE: 25392039606.17, Time to Converge: 57.5660 seconds\n",
        "2. Cosine K-means - Iterations: 59, SSE: 682.22, Time to Converge: 124.8682 seconds\n",
        "3. Jaccard K-means - Iterations: 69, SSE: 3660.35, Time to Converge: 182.2073 seconds\n",
        "\n",
        "We see that Euclidean Kmeans take the least amount iterations and the time to coverge, Euclidean distance is sensitive to the scale of features. The high SSE may indicate that the algorithm struggles to converge when dealing with data that has varying feature scales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sWALWNHEfROS",
        "outputId": "7f030375-5316-42ce-a10f-bf1f8021747c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Euclidean K-means - SSE: 25373275133.23\n",
            "Cosine K-means - SSE: 684.57\n",
            "Jaccard K-means - SSE: 3708.24\n"
          ]
        }
      ],
      "source": [
        "# K-means algorithm with stop criteria\n",
        "def k_means_stop_criteria(data, k, distance_function, max_iters=100, tolerance=1e-4):\n",
        "    n_samples, n_features = data.shape\n",
        "    centroids = data[np.random.choice(n_samples, k, replace=False)]\n",
        "    assigned_labels = np.zeros(n_samples)\n",
        "\n",
        "    for iter_count in range(max_iters):\n",
        "        for i in range(n_samples):\n",
        "            distances = [distance_function(data[i], centroid) for centroid in centroids]\n",
        "            assigned_labels[i] = np.argmin(distances)\n",
        "\n",
        "        new_centroids = np.array([np.mean(data[assigned_labels == j], axis=0) for j in range(k)])\n",
        "\n",
        "        # Check stop criteria\n",
        "        if np.all(np.abs(new_centroids - centroids) < tolerance):\n",
        "            break\n",
        "\n",
        "        # Update centroids for the next iteration\n",
        "        centroids = new_centroids\n",
        "\n",
        "\n",
        "    sse = sum([distance_function(data[i], centroids[int(assigned_labels[i])])**2 for i in range(n_samples)])\n",
        "\n",
        "    return assigned_labels, centroids, iter_count + 1, sse\n",
        "\n",
        "\n",
        "distance_functions = [euclidean_distance, cosine_similarity, jaccard_similarity]\n",
        "distance_function_names = ['Euclidean', 'Cosine', 'Jaccard']\n",
        "\n",
        "\n",
        "sse_results = {}\n",
        "\n",
        "for distance_function, distance_function_name in zip(distance_functions, distance_function_names):\n",
        "    # Run K-means with stop criteria\n",
        "    cluster_labels, cluster_centroids, num_iterations, sse = k_means_stop_criteria(data, k, distance_function)\n",
        "\n",
        "    sse_results[distance_function_name] = sse\n",
        "\n",
        "# Display SSEs\n",
        "for method, sse in sse_results.items():\n",
        "    print(f\"{method} K-means - SSE: {sse:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odvy0mCSMUBH"
      },
      "source": [
        "Q4 The results that we see are\n",
        "1. Euclidean K-means - SSE: 25373275133.23\n",
        "2. Cosine K-means - SSE: 684.57\n",
        "3. Jaccard K-means - SSE: 3708.24\n",
        "\n",
        "SSE values reflect how well the K-means algorithm is able to minimize the sum of squared distances between data points and their assigned cluster centroids. The choice of distance function significantly influences the clustering performance, and the characteristics of the data, such as feature scales and inherent structure, play a crucial role in determining the SSE values for each distance metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW_K6BmgM57r"
      },
      "source": [
        "Q5\n",
        "* Euclidean distance, being sensitive to feature scale, leads to suboptimal clustering results.\n",
        "* Cosine and Jaccard distance metrics, while having lower SSE, still exhibit challenges in capturing the underlying cluster structure.\n",
        "* The use of majority voting improves accuracy in all cases.\n",
        "* Euclidean K-means converges faster than Cosine and Jaccard K-means with stop criteria."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
